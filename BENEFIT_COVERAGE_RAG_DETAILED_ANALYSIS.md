# Benefit Coverage RAG Agent - Comprehensive Technical Analysis

## ğŸ“‹ Table of Contents
1. [System Architecture Overview](#system-architecture-overview)
2. [Complete Data Flow](#complete-data-flow)
3. [Storage Paths & Data Locations](#storage-paths--data-locations)
4. [RAG Strategy Deep Dive](#rag-strategy-deep-dive)
5. [Chunking Strategy Detailed](#chunking-strategy-detailed)
6. [Missing Components & Gaps](#missing-components--gaps)
7. [Performance Optimization Opportunities](#performance-optimization-opportunities)

---

## 1. System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BENEFIT COVERAGE RAG AGENT ARCHITECTURE               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER REQUEST
    â”‚
    â”œâ”€â”€â–º PREPARE MODE: Upload PDF â†’ Index for RAG
    â”‚    â”‚
    â”‚    â”œâ”€[1]â”€â–º S3 Upload (PDF)
    â”‚    â”œâ”€[2]â”€â–º AWS Textract Processing (Lambda Trigger)
    â”‚    â”œâ”€[3]â”€â–º RAG Pipeline Preparation
    â”‚    â””â”€[4]â”€â–º Vector Store Indexing
    â”‚
    â””â”€â”€â–º QUERY MODE: Ask Questions â†’ Get Answers
         â”‚
         â”œâ”€[1]â”€â–º Query Embedding Generation
         â”œâ”€[2]â”€â–º Semantic Search (Vector Similarity)
         â”œâ”€[3]â”€â–º Document Reranking (Cohere)
         â”œâ”€[4]â”€â–º Answer Generation (Claude LLM)
         â””â”€[5]â”€â–º Response with Sources
```

### Component Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Orchestration** | Strands Agent Framework | Multi-tool coordination |
| **LLM** | AWS Bedrock Claude 3.5 Sonnet | Answer generation |
| **Embeddings** | AWS Bedrock Titan v2 (1024-dim) | Vector representation |
| **Reranking** | AWS Bedrock Cohere Rerank v3.5 | Relevance optimization |
| **Vector Store** | Qdrant | Semantic search index |
| **Text Extraction** | AWS Textract | PDF â†’ JSON conversion |
| **Storage** | AWS S3 | Document storage |
| **Logging** | Python logging + structured logs | Observability |

---

## 2. Complete Data Flow

### ğŸ”„ PREPARATION PIPELINE (Indexing Phase)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: PDF UPLOAD & TEXTRACT PROCESSING                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[USER] Upload PDF via Streamlit
   â”‚
   â”œâ”€â–º Save to temp file (tmpXXXXX.pdf)
   â”‚
   â”œâ”€â–º Upload to S3
   â”‚   Location: s3://mb-assistant-bucket/mba/pdf/{filename}.pdf
   â”‚   Metadata: {original_filename, document_type, workflow}
   â”‚
   â””â”€â–º S3 Event Trigger â†’ Lambda Function
       â”‚
       â”œâ”€â–º Lambda: mba-ingest-lambda
       â”‚   - Decodes URL-encoded S3 key (fixes spaces/special chars)
       â”‚   - Calls AWS Textract.start_document_analysis()
       â”‚   - Textract processes PDF asynchronously
       â”‚
       â””â”€â–º Textract Output Stored
           Location: s3://mb-assistant-bucket/mba/textract-output/mba/pdf/{filename}/{job_id}/
           Files:
              - page_0001.json  (Textract blocks for page 1)
              - page_0002.json  (Textract blocks for page 2)
              - ...
              - manifest.json   (Optional metadata)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2: TEXT EXTRACTION FROM TEXTRACT OUTPUT                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[RAG Agent] extract_text_from_textract_s3()
   â”‚
   â”œâ”€â–º Auto-detect Textract output path
   â”‚   Function: find_textract_output_path()
   â”‚   - Lists S3 objects with delimiter='/' to find subfolders
   â”‚   - Detects job ID subfolders automatically
   â”‚   - Returns: mba/textract-output/mba/pdf/{filename}/{job_id}/
   â”‚
   â”œâ”€â–º List all page_*.json files
   â”‚   Pattern matching:
   â”‚   - page_*.json (e.g., page_0001.json)
   â”‚   - Files with digits in filename
   â”‚   Excludes: manifest.json, metadata.json, consolidated.json
   â”‚
   â”œâ”€â–º Process each page JSON file
   â”‚   For each page:
   â”‚   â”œâ”€â–º Download JSON from S3
   â”‚   â”œâ”€â–º Parse Textract Blocks:
   â”‚   â”‚   - LINE blocks â†’ Extract text content
   â”‚   â”‚   - TABLE blocks â†’ Mark as [TABLE: {id}]
   â”‚   â”‚   - FORM blocks â†’ (Currently not extracted)
   â”‚   â”œâ”€â–º Extract page number from filename (page_0001 â†’ 1)
   â”‚   â””â”€â–º Create Document object:
   â”‚       {
   â”‚         page_content: "extracted text...",
   â”‚         metadata: {
   â”‚           source: "s3_key_path",
   â”‚           page: 1,
   â”‚           s3_bucket: "mb-assistant-bucket",
   â”‚           s3_key: "full_s3_key",
   â”‚           has_tables: true/false
   â”‚         }
   â”‚       }
   â”‚
   â””â”€â–º Return List[Document]
       Output: documents[] (one per page)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3: INTELLIGENT DOCUMENT CHUNKING                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[RAG Agent] chunk_documents()
   â”‚
   â”œâ”€â–º For each document (page):
   â”‚   â”‚
   â”‚   â”œâ”€â–º Split by paragraph boundaries (double newline)
   â”‚   â”‚   Regex: r'\n\s*\n'
   â”‚   â”‚
   â”‚   â”œâ”€â–º For each paragraph:
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º Detect content type:
   â”‚   â”‚   â”‚   â”œâ”€â–º TABLE/CPT: Contains pipe delimiters |, CPT codes, multi-column layout
   â”‚   â”‚   â”‚   â”œâ”€â–º SPARSE: Less than 20 words
   â”‚   â”‚   â”‚   â””â”€â–º NORMAL: Regular narrative text
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º Determine adaptive chunk size:
   â”‚   â”‚   â”‚   â”œâ”€â–º TABLE/CPT: 600 characters (smaller for dense content)
   â”‚   â”‚   â”‚   â”œâ”€â–º SPARSE: 1500 characters (larger for sparse content)
   â”‚   â”‚   â”‚   â””â”€â–º NORMAL: 1000 characters (default)
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º Extract metadata enrichment:
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â”œâ”€â–º section_title: Detected from markdown headers (# Title)
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â”œâ”€â–º benefit_category: Pattern matching
   â”‚   â”‚   â”‚   â”‚   - "Therapy Services" (therapy, physical therapy keywords)
   â”‚   â”‚   â”‚   â”‚   - "Diagnostic Services" (diagnostic, imaging, MRI keywords)
   â”‚   â”‚   â”‚   â”‚   - "Preventive Care" (preventive, wellness, screening)
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â”œâ”€â–º coverage_type:
   â”‚   â”‚   â”‚   â”‚   - "covered" (covered, eligible, benefit keywords)
   â”‚   â”‚   â”‚   â”‚   - "excluded" (excluded, not covered, limitation)
   â”‚   â”‚   â”‚   â”‚   - "prior_auth_required" (prior authorization, preauthorization)
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â”œâ”€â–º cpt_codes: Extract 5-digit codes (e.g., 97124)
   â”‚   â”‚   â”‚   â”‚   - Limited to 10 codes per chunk
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â””â”€â–º has_cost_info: Boolean (contains $ amounts)
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º Build chunk with overlap:
   â”‚   â”‚   â”‚   - Add paragraph to current chunk
   â”‚   â”‚   â”‚   - If exceeds adaptive size â†’ create new chunk
   â”‚   â”‚   â”‚   - No explicit overlap implementation (âŒ GAP)
   â”‚   â”‚   â”‚
   â”‚   â”‚   â””â”€â–º Create Document object for chunk:
   â”‚   â”‚       {
   â”‚   â”‚         page_content: "chunk text...",
   â”‚   â”‚         metadata: {
   â”‚   â”‚           ...base_metadata,
   â”‚   â”‚           section_title: "...",
   â”‚   â”‚           benefit_category: "...",
   â”‚   â”‚           coverage_type: "...",
   â”‚   â”‚           cpt_codes: [...],
   â”‚   â”‚           has_cost_info: true
   â”‚   â”‚         }
   â”‚   â”‚       }
   â”‚   â”‚
   â”‚   â””â”€â–º Aggregate all chunks
   â”‚
   â””â”€â–º Return List[Document] (chunks)
       Statistics:
       - Total chunks created
       - Min/Max/Average chunk size
       - Chunks with CPT codes
       - Chunks with benefit categories

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 4: EMBEDDING GENERATION                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[RAG Agent] get_bedrock_embeddings()
   â”‚
   â”œâ”€â–º For each chunk text:
   â”‚   â”‚
   â”‚   â”œâ”€â–º Truncate to 8000 characters (Titan limit)
   â”‚   â”‚   âš ï¸  Warning logged if truncation occurs
   â”‚   â”‚
   â”‚   â”œâ”€â–º Call AWS Bedrock Titan Embeddings API:
   â”‚   â”‚   Model: amazon.titan-embed-text-v2:0
   â”‚   â”‚   Input: {"inputText": truncated_text}
   â”‚   â”‚   Output: 1024-dimensional vector
   â”‚   â”‚   API: bedrock_runtime.invoke_model()
   â”‚   â”‚
   â”‚   â”œâ”€â–º Parse response:
   â”‚   â”‚   embedding = result['embedding']  # List[float], length 1024
   â”‚   â”‚
   â”‚   â”œâ”€â–º Error handling:
   â”‚   â”‚   On failure â†’ Use zero vector [0.0] * 1024 as fallback
   â”‚   â”‚   âš ï¸  This may cause poor search results (âŒ CONCERN)
   â”‚   â”‚
   â”‚   â””â”€â–º Append to embeddings list
   â”‚
   â””â”€â–º Return List[List[float]]
       Dimensions: [num_chunks x 1024]
       Statistics:
       - Successfully generated embeddings
       - Fallback vectors used (should be 0)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 5: VECTOR STORE INDEXING (QDRANT)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[RAG Agent] Index in Qdrant
   â”‚
   â”œâ”€â–º Connect to Qdrant:
   â”‚   URL: settings.qdrant_url (e.g., http://localhost:6333)
   â”‚   API Key: settings.qdrant_api_key
   â”‚   Timeout: 60 seconds
   â”‚
   â”œâ”€â–º Check/Create collection:
   â”‚   Collection name: benefit_coverage_rag_index (default)
   â”‚   â”‚
   â”‚   â”œâ”€â–º List existing collections
   â”‚   â”‚
   â”‚   â”œâ”€â–º If collection doesn't exist:
   â”‚   â”‚   Create with:
   â”‚   â”‚   - Vector size: 1024 (Titan embedding dimension)
   â”‚   â”‚   - Distance metric: COSINE
   â”‚   â”‚   - Schema: vectors_config = VectorParams(size=1024, distance=Distance.COSINE)
   â”‚   â”‚
   â”‚   â””â”€â–º If exists: Use existing (upsert mode)
   â”‚
   â”œâ”€â–º Build vector points:
   â”‚   For each (chunk, embedding) pair:
   â”‚   â”‚
   â”‚   â”œâ”€â–º Generate deterministic ID:
   â”‚   â”‚   content_hash = SHA256(chunk.page_content)
   â”‚   â”‚   uid = UUID(content_hash[:32])
   â”‚   â”‚   Purpose: Deduplication (same content = same ID)
   â”‚   â”‚
   â”‚   â”œâ”€â–º Create PointStruct:
   â”‚   â”‚   {
   â”‚   â”‚     id: uid,
   â”‚   â”‚     vector: embedding,  # 1024-dim float array
   â”‚   â”‚     payload: {
   â”‚   â”‚       "text": chunk.page_content,
   â”‚   â”‚       "source": "s3_key",
   â”‚   â”‚       "page": 1,
   â”‚   â”‚       "s3_bucket": "...",
   â”‚   â”‚       "s3_key": "...",
   â”‚   â”‚       "has_tables": true,
   â”‚   â”‚       "benefit_category": "Therapy Services",
   â”‚   â”‚       "coverage_type": "covered",
   â”‚   â”‚       "cpt_codes": ["97124", "97110"],
   â”‚   â”‚       "has_cost_info": true
   â”‚   â”‚     }
   â”‚   â”‚   }
   â”‚   â”‚
   â”‚   â””â”€â–º Add to points list
   â”‚
   â”œâ”€â–º Bulk upsert to Qdrant:
   â”‚   qdrant_client.upsert(
   â”‚     collection_name=index_name,
   â”‚     points=points
   â”‚   )
   â”‚   Note: Upsert = insert or update based on ID
   â”‚   - Same ID â†’ Updates existing point
   â”‚   - New ID â†’ Inserts new point
   â”‚
   â”œâ”€â–º Verify indexing:
   â”‚   Get collection info:
   â”‚   - Total vectors count
   â”‚   - Vector dimension
   â”‚   - Distance metric
   â”‚
   â””â”€â–º Return success response:
       {
         "success": true,
         "message": "Processed 15 docs into 67 chunks",
         "chunks_count": 67,
         "doc_count": 15,
         "index_name": "benefit_coverage_rag_index"
       }
```

### ğŸ” QUERY PIPELINE (Retrieval Phase)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: QUERY EMBEDDING GENERATION                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[USER] Asks question: "Is massage therapy covered?"
   â”‚
   â”œâ”€â–º Generate query embedding:
   â”‚   Function: get_bedrock_embeddings([question])
   â”‚   Model: amazon.titan-embed-text-v2:0
   â”‚   Input: "Is massage therapy covered?"
   â”‚   Output: 1024-dimensional vector
   â”‚
   â””â”€â–º query_embedding = [0.0234, -0.0156, ...]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: SEMANTIC SEARCH (VECTOR SIMILARITY)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[RAG Agent] Search Qdrant
   â”‚
   â”œâ”€â–º Connect to Qdrant:
   â”‚   URL: settings.qdrant_url
   â”‚   Collection: benefit_coverage_rag_index
   â”‚
   â”œâ”€â–º Perform vector similarity search:
   â”‚   qdrant_client.search(
   â”‚     collection_name=index_name,
   â”‚     query_vector=query_embedding,  # 1024-dim
   â”‚     limit=k  # Default: 5
   â”‚   )
   â”‚
   â”‚   Search algorithm:
   â”‚   - Cosine similarity between query vector and all indexed vectors
   â”‚   - Returns top-k most similar results
   â”‚   - Sorted by descending similarity score
   â”‚
   â”œâ”€â–º Parse search results:
   â”‚   For each hit:
   â”‚   {
   â”‚     score: 0.8734,  # Cosine similarity (0-1)
   â”‚     payload: {
   â”‚       "text": "Massage Therapy is covered...",
   â”‚       "source": "page_0001.json",
   â”‚       "page": 1,
   â”‚       "benefit_category": "Therapy Services",
   â”‚       "cpt_codes": ["97124"],
   â”‚       ...metadata...
   â”‚     }
   â”‚   }
   â”‚
   â””â”€â–º Return retrieved_docs[]
       Count: k documents (default 5)
       Ordered by: Initial cosine similarity score

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: DOCUMENT RERANKING (COHERE)                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[RAG Agent] rerank_documents()
   â”‚
   â”œâ”€â–º Prepare for reranking:
   â”‚   Query: "Is massage therapy covered?"
   â”‚   Documents: [doc1.text, doc2.text, ..., doc5.text]
   â”‚   Top N: 5 (same as k)
   â”‚
   â”œâ”€â–º Call AWS Bedrock Cohere Rerank API:
   â”‚   Model: cohere.rerank-v3-5:0
   â”‚   Payload:
   â”‚   {
   â”‚     "api_version": 2,
   â”‚     "query": question,
   â”‚     "documents": document_texts[],
   â”‚     "top_n": 5
   â”‚   }
   â”‚
   â”‚   Reranking process:
   â”‚   - Cohere analyzes semantic relevance between query and each document
   â”‚   - Considers context, keywords, intent
   â”‚   - More sophisticated than simple vector similarity
   â”‚   - Returns relevance scores (0-1)
   â”‚
   â”œâ”€â–º Parse reranking results:
   â”‚   [
   â”‚     {"index": 0, "relevance_score": 0.9876},  # Most relevant
   â”‚     {"index": 1, "relevance_score": 0.8234},
   â”‚     {"index": 2, "relevance_score": 0.5612},
   â”‚     {"index": 3, "relevance_score": 0.3421},
   â”‚     {"index": 4, "relevance_score": 0.1234}
   â”‚   ]
   â”‚
   â”œâ”€â–º Reorder documents by reranking scores:
   â”‚   reranked_docs = [
   â”‚     retrieved_docs[0],  # Highest relevance
   â”‚     retrieved_docs[1],
   â”‚     retrieved_docs[2],
   â”‚     retrieved_docs[3],
   â”‚     retrieved_docs[4]
   â”‚   ]
   â”‚
   â””â”€â–º Error handling:
       On failure â†’ Return original order (no reranking)
       âš ï¸  Fallback may reduce answer quality

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: ANSWER GENERATION (CLAUDE LLM)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[RAG Agent] query_bedrock_llm()
   â”‚
   â”œâ”€â–º Construct prompt:
   â”‚   Template:
   â”‚   """
   â”‚   Answer the question based on the provided context from benefit coverage policy documents.
   â”‚
   â”‚   Context:
   â”‚   {concatenated reranked documents}
   â”‚
   â”‚   Question: {user_question}
   â”‚
   â”‚   Answer:
   â”‚   """
   â”‚
   â”œâ”€â–º Call AWS Bedrock Claude API:
   â”‚   Model: settings.bedrock_model_id
   â”‚          (e.g., anthropic.claude-3-5-sonnet-20240620-v1:0)
   â”‚
   â”‚   Payload:
   â”‚   {
   â”‚     "anthropic_version": "bedrock-2023-05-31",
   â”‚     "max_tokens": 2000,
   â”‚     "temperature": 0.3,  # Low temp for factual answers
   â”‚     "messages": [
   â”‚       {
   â”‚         "role": "user",
   â”‚         "content": full_prompt
   â”‚       }
   â”‚     ]
   â”‚   }
   â”‚
   â”‚   Model behavior:
   â”‚   - Reads context from reranked documents
   â”‚   - Synthesizes comprehensive answer
   â”‚   - Cites specific policy language
   â”‚   - Includes relevant details (limits, costs, CPT codes)
   â”‚
   â”œâ”€â–º Parse LLM response:
   â”‚   answer_text = result['content'][0]['text']
   â”‚   Example:
   â”‚   "Massage therapy is covered with a limit of 6 visits per
   â”‚    calendar year. Cost-sharing: $20 copay PPO, $40 copay PAR..."
   â”‚
   â””â”€â–º Error handling:
       On failure â†’ Return error message
       "Error generating answer: {error_detail}"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: FORMAT RESPONSE WITH SOURCES                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[RAG Agent] Format final response
   â”‚
   â”œâ”€â–º Build sources array:
   â”‚   For each reranked document:
   â”‚   {
   â”‚     "source_id": 1,
   â”‚     "content": doc.text[:500] + "...",  # Truncated to 500 chars
   â”‚     "metadata": {
   â”‚       "source": "page_0001.json",
   â”‚       "page": 1,
   â”‚       "s3_bucket": "mb-assistant-bucket",
   â”‚       "benefit_category": "Therapy Services",
   â”‚       "cpt_codes": ["97124"],
   â”‚       ...
   â”‚     }
   â”‚   }
   â”‚
   â””â”€â–º Return complete response:
       {
         "success": true,
         "answer": "Massage therapy is covered...",
         "sources": [
           {
             "source_id": 1,
             "content": "...",
             "metadata": {...}
           },
           ...
         ],
         "question": "Is massage therapy covered?",
         "retrieved_docs_count": 5
       }
```

---

## 3. Storage Paths & Data Locations

### ğŸ“ S3 Bucket Structure

```
s3://mb-assistant-bucket/
â”œâ”€â”€ mba/
â”‚   â”œâ”€â”€ pdf/                                    # Original PDFs
â”‚   â”‚   â”œâ”€â”€ benefit_coverage.pdf
â”‚   â”‚   â””â”€â”€ Aetna Medicare Eagle Plan H5521-241 (PPO).pdf
â”‚   â”‚
â”‚   â”œâ”€â”€ textract-output/                        # Textract processed results
â”‚   â”‚   â””â”€â”€ mba/
â”‚   â”‚       â””â”€â”€ pdf/
â”‚   â”‚           â”œâ”€â”€ benefit_coverage.pdf/
â”‚   â”‚           â”‚   â””â”€â”€ {job_id}/               # Job-specific subfolder
â”‚   â”‚           â”‚       â”œâ”€â”€ manifest.json        # Optional metadata
â”‚   â”‚           â”‚       â”œâ”€â”€ page_0001.json       # Page 1 Textract blocks
â”‚   â”‚           â”‚       â”œâ”€â”€ page_0002.json
â”‚   â”‚           â”‚       â””â”€â”€ ...
â”‚   â”‚           â”‚
â”‚   â”‚           â””â”€â”€ Aetna Medicare Eagle Plan H5521-241 (PPO).pdf/
â”‚   â”‚               â””â”€â”€ {job_id}/
â”‚   â”‚                   â”œâ”€â”€ page_0001.json
â”‚   â”‚                   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ csv/                                    # CSV data files (other agents)
â”‚       â””â”€â”€ ...
```

### ğŸ—„ï¸ Qdrant Vector Store Structure

```
Qdrant Instance: http://localhost:6333 (or cloud URL)

Collections:
â”œâ”€â”€ benefit_coverage_rag_index (default)
â”‚   â”œâ”€â”€ Vectors: 1024-dimensional (Titan v2)
â”‚   â”œâ”€â”€ Distance: COSINE
â”‚   â”œâ”€â”€ Points: ~67 per document (varies by size)
â”‚   â”‚
â”‚   â””â”€â”€ Point Structure:
â”‚       {
â”‚         id: "uuid-based-on-content-hash",
â”‚         vector: [0.023, -0.015, ...],  # 1024 dims
â”‚         payload: {
â”‚           text: "chunk content",
â”‚           source: "s3_key",
â”‚           page: 1,
â”‚           s3_bucket: "mb-assistant-bucket",
â”‚           s3_key: "full_path",
â”‚           has_tables: true,
â”‚           benefit_category: "Therapy Services",
â”‚           coverage_type: "covered",
â”‚           cpt_codes: ["97124"],
â”‚           has_cost_info: true
â”‚         }
â”‚       }
â”‚
â””â”€â”€ [other collections for different document sets]
```

### ğŸ’¾ Local Storage (Temporary)

```
Temp Files (Streamlit uploads):
/tmp/
â”œâ”€â”€ tmpXXXXXX.pdf       # User-uploaded PDFs (deleted after upload to S3)
â””â”€â”€ ...
```

---

## 4. RAG Strategy Deep Dive

### ğŸ¯ RAG Approach: **Hybrid Semantic + Metadata-Enhanced RAG**

#### Architecture Pattern
- **Type**: Dense Passage Retrieval (DPR) + Reranking
- **Embedding Model**: AWS Bedrock Titan v2 (1024-dim)
- **Vector Store**: Qdrant (cosine similarity)
- **Reranker**: AWS Bedrock Cohere Rerank v3.5
- **Generator**: AWS Bedrock Claude 3.5 Sonnet

#### Two-Stage Retrieval Process

**Stage 1: Semantic Search (Vector Similarity)**
- Converts query to 1024-dim embedding
- Performs cosine similarity search in Qdrant
- Retrieves top-k candidates (default: 5)
- **Advantage**: Fast, scales well, captures semantic meaning
- **Limitation**: May miss exact keyword matches

**Stage 2: Reranking (Cross-Encoder)**
- Uses Cohere Rerank v3.5 for fine-grained relevance scoring
- Analyzes query-document pairs with attention mechanism
- **Advantage**: More accurate relevance scores than similarity alone
- **Limitation**: Slower, requires API calls

### ğŸ“Š Metadata-Enhanced Retrieval

Current implementation enriches chunks with:
- `benefit_category`: Therapy Services, Diagnostic Services, Preventive Care
- `coverage_type`: covered, excluded, prior_auth_required
- `cpt_codes`: Extracted procedure codes
- `has_cost_info`: Presence of cost information
- `source`, `page`: Document provenance

**Potential (not yet implemented):**
- Could filter by metadata before semantic search
- Example: `filter_by_category("Therapy Services")` â†’ only search therapy chunks
- âŒ **GAP**: No metadata filtering in query stage

---

## 5. Chunking Strategy Detailed

### ğŸ§© Intelligent Adaptive Chunking

#### Strategy Overview
**Name**: Content-Aware Paragraph-Based Chunking with Adaptive Sizing

#### Algorithm Steps

1. **Paragraph Detection**
   - Split document by double newlines: `r'\n\s*\n'`
   - Preserves natural paragraph boundaries
   - Maintains readability and context

2. **Content Type Classification**
   ```python
   if is_table(para) or has_cpt_codes(para):
       chunk_size = 600  # Dense technical content
   elif word_count < 20:
       chunk_size = 1500  # Sparse content (headers, bullets)
   else:
       chunk_size = 1000  # Normal narrative text
   ```

3. **Table Detection Logic**
   - Pipe delimiters: `|column1|column2|`
   - CPT code patterns: `\bCPT\b.*\d{5}`
   - Multiple whitespace columns: `\s{3,}` repeated

4. **Metadata Extraction Per Chunk**
   - Regex patterns for section titles, categories, codes
   - Enriches each chunk independently
   - Metadata accumulates as paragraphs added to chunk

5. **Chunk Creation**
   - Add paragraphs to current chunk
   - If exceeds adaptive size â†’ create new chunk
   - Start new chunk with current paragraph
   - âŒ **NO OVERLAP IMPLEMENTATION** (Gap!)

#### Chunking Statistics (Example)
```
Documents: 15 pages
Chunks: 67 total
Average per page: 4.5 chunks
Min chunk: 456 chars
Max chunk: 1498 chars
Average chunk: 892 chars

Distribution:
- TABLE/CPT: ~23 chunks (600 char target)
- SPARSE: ~12 chunks (1500 char target)
- NORMAL: ~32 chunks (1000 char target)
```

### âš™ï¸ Chunking Parameters

| Parameter | Default | Purpose |
|-----------|---------|---------|
| `chunk_size` | 1000 | Default target chunk size (characters) |
| `chunk_overlap` | 200 | **NOT IMPLEMENTED** âŒ |
| Adaptive sizes | 600/1000/1500 | Content-type specific |

---

## 6. Missing Components & Gaps

### âŒ Critical Gaps

#### 1. **No Chunk Overlap Implementation**
**Current**: Hard paragraph boundaries, no overlap
**Impact**: May lose context at chunk boundaries
**Fix**:
```python
# Proposed implementation
if current_chunk:
    overlap_text = current_chunk[-chunk_overlap:]
    new_chunk = overlap_text + "\n\n" + para
```

#### 2. **No Metadata Filtering in Query Stage**
**Current**: Searches all chunks regardless of category
**Impact**: May retrieve irrelevant chunks
**Fix**:
```python
# Add Qdrant filter
filter = Filter(
    must=[
        FieldCondition(
            key="benefit_category",
            match=MatchValue(value="Therapy Services")
        )
    ]
)
search_results = qdrant_client.search(
    collection_name=index_name,
    query_vector=query_embedding,
    query_filter=filter,  # Add filtering
    limit=k
)
```

#### 3. **Zero Vector Fallback on Embedding Failure**
**Current**: Uses `[0.0] * 1024` on API error
**Impact**: Dead chunks that never match queries
**Fix**:
```python
# Skip failed chunks instead
if embedding_generation_failed:
    logger.error(f"Skipping chunk {idx} due to embedding failure")
    continue  # Don't index this chunk
```

#### 4. **No Query Intent Classification**
**Current**: Treats all queries the same
**Impact**: Can't optimize retrieval for different query types
**Fix**:
```python
# Classify query intent
intent = classify_query(question)
# "coverage_status", "cost_inquiry", "procedure_code", "limit_inquiry"

if intent == "procedure_code":
    # Filter by cpt_codes metadata
    filter_by_cpt_codes(extracted_codes)
```

#### 5. **No Table Structure Preservation**
**Current**: Tables marked as `[TABLE: {id}]` but structure lost
**Impact**: Can't answer table-based queries accurately
**Fix**:
```python
# Extract table structure from Textract
if block_type == 'TABLE':
    table_cells = extract_table_cells(block)
    formatted_table = format_as_markdown(table_cells)
    text_lines.append(formatted_table)
```

#### 6. **No Query Result Caching**
**Current**: Every query regenerates embeddings and searches
**Impact**: Slower response for repeat/similar queries
**Fix**:
```python
# Add Redis/local cache
cache_key = hash(question + index_name)
if cached_result := query_cache.get(cache_key):
    return cached_result
```

#### 7. **No Multi-Query Support**
**Current**: Single query at a time
**Impact**: Can't handle complex questions
**Fix**:
```python
# Generate multiple query variants
variants = generate_query_variants(question)
# "Is massage therapy covered?"
# â†’ ["massage therapy coverage", "massage benefit eligibility", "97124 cpt code"]

all_results = []
for variant in variants:
    results = search(variant)
    all_results.extend(results)

# Deduplicate and rerank all_results
```

#### 8. **No Hybrid Search (Vector + Keyword)**
**Current**: Pure semantic search only
**Impact**: May miss exact keyword matches
**Fix**:
```python
# Combine vector and BM25 scores
vector_results = semantic_search(query_embedding, k=20)
keyword_results = bm25_search(question, k=20)

# Reciprocal Rank Fusion (RRF)
combined_scores = rrf_fusion(vector_results, keyword_results)
final_results = top_k(combined_scores, k=5)
```

### âš ï¸ Missing Features (Non-Critical)

#### 9. **No Conversation History/Context**
**Current**: Each query is independent
**Impact**: Can't handle follow-up questions
**Example**:
```
Q1: "Is massage therapy covered?"
Q2: "What are the visit limits?"  â† No context that this refers to massage therapy
```

#### 10. **No Source Deduplication in Response**
**Current**: May return same source chunk multiple times
**Impact**: Redundant sources in response

#### 11. **No Query Performance Metrics**
**Current**: No tracking of:
- Query latency
- Retrieval accuracy
- User satisfaction
**Impact**: Can't measure/optimize system performance

#### 12. **No Document Update/Versioning**
**Current**: Can't update indexed documents
**Impact**: Old policy data persists

#### 13. **No Multi-Document Queries**
**Current**: Searches single index only
**Impact**: Can't compare across multiple policies

---

## 7. Performance Optimization Opportunities

### ğŸš€ Immediate Wins

1. **Batch Embedding Generation**
   ```python
   # Current: One API call per chunk
   for chunk in chunks:
       embedding = get_bedrock_embeddings([chunk])

   # Optimized: Batch API calls
   batch_size = 10
   for i in range(0, len(chunks), batch_size):
       batch = chunks[i:i+batch_size]
       embeddings = get_bedrock_embeddings(batch)
   ```

2. **Parallel Textract Processing**
   ```python
   # Use asyncio for parallel S3 downloads
   import asyncio
   async def process_pages(page_files):
       tasks = [download_and_process(pf) for pf in page_files]
       results = await asyncio.gather(*tasks)
   ```

3. **Qdrant Batch Upsert Optimization**
   ```python
   # Already implemented, but could batch larger
   # Current: All points in one upsert
   # Consider: Batch of 100 points at a time for large docs
   ```

4. **Query Result Caching (Redis)**
   ```python
   import redis
   cache = redis.Redis(host='localhost', port=6379)

   cache_key = f"rag_query:{hash(question)}:{index_name}"
   if cached := cache.get(cache_key):
       return json.loads(cached)

   # Cache for 1 hour
   cache.setex(cache_key, 3600, json.dumps(result))
   ```

5. **Lazy Initialization (Already Implemented)**
   - Agent loads only on first use
   - Good for Lambda cold starts

### ğŸ”§ Advanced Optimizations

6. **Quantized Vectors (Reduce Memory)**
   - Use `int8` quantization for vectors
   - 4x memory reduction
   - Minimal accuracy loss

7. **Approximate Nearest Neighbor (ANN)**
   - Qdrant uses HNSW by default (already optimized)
   - Tune HNSW parameters for speed/accuracy tradeoff

8. **Streaming Responses**
   - Stream answer generation token-by-token
   - Better UX for long answers

9. **Precompute Popular Queries**
   - Identify common questions
   - Precompute and cache results

10. **Multi-Region Bedrock**
    - Use cross-region inference profiles
    - Reduce latency and throttling

---

## ğŸ“ Summary

### âœ… What's Working Well
- Comprehensive logging at every step
- Intelligent adaptive chunking
- Auto-detection of Textract job subfolders
- Metadata enrichment (categories, CPT codes, cost info)
- Two-stage retrieval (semantic + reranking)
- Deterministic document IDs (deduplication)

### âŒ Critical Gaps to Address
1. No chunk overlap â†’ Context loss at boundaries
2. No metadata filtering â†’ Suboptimal retrieval
3. Zero vector fallback â†’ Dead chunks
4. No table structure preservation â†’ Lost information
5. No query caching â†’ Slow repeat queries

### ğŸ”® Future Enhancements
- Hybrid search (vector + keyword)
- Multi-query expansion
- Conversation context/history
- Query intent classification
- Performance metrics and monitoring
- Document versioning and updates

---

## ğŸ¯ Recommended Next Steps

### Priority 1: Fix Critical Gaps
1. Implement chunk overlap
2. Add metadata filtering to queries
3. Remove zero vector fallback
4. Add table structure extraction

### Priority 2: Performance
1. Add query result caching
2. Batch embedding generation
3. Parallel Textract processing

### Priority 3: Features
1. Hybrid search
2. Query intent classification
3. Conversation history

---

**Document Version**: 1.0
**Date**: 2025-10-19
**Author**: System Analysis
**Status**: Complete